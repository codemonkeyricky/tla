% \begin{document}

\chapter{Simple Scheduler}

Task schedulers are fairly ubiquitous. Every device implements
\textit{something} to manage tasks. Modern desktop or mobile device processes
are non-trivial OS abstractions. Every process maintains its own virtual memory
space for security reasons. Context switching process requires the OS to "clean"
the hardware before running the new process.\newline

For embedded devices such as hard drives or network cards, the security
consideration may be relaxed as users are typically not allowed to run arbitrary
code on the device. Sometimes these products don't have a full-blown operating
system to save on memory and storage footprint, but still need some sort of
scheduler to manage the tasks.\newline

To solve the C10k \cite{c10k} problem, some languages (eg. Rust) support 
asynchronous programming, allowing the user to enable task switching \textit{within} in the same process to scale up system throughput. However,
language like Rust only provides the \textit{language support} for asynchronous
programming, and user must supply their async runtime. The async runtime
must also include a scheduler to manage the tasks.\newline

Hopefully, this provides enough context as to why implementing a scheduler may be of
interest. In this chapter, we will implement a very simple cooperative
scheduler with tasks that share a single lock.

\section{Design}

In this section we will define a spec for a simple task scheduler. The task sechdeuler has the following
requirements:
\begin{itemize}
    \item Supporting N execution context (ie. CPUs)
    \item Supporting T number of tasks
    \item Tasks have identical priority and are scheduled coopertively
    \item System has a single global lock
    \item Any task can attempt to acquire the lock, Any task attempting to
    acquire the lock are gauranteed to be scheduled.
    \item If multiple tasks attempt to grab the lock, the tasks will be
    scheduled in lock request order. 
\end{itemize}

\section{Spec}

We will model scheduler using the following variables:\newline
\begin{tla}
Init ==
    /\ cpus = [i \in 0..N-1 |-> ""] 
    /\ ready_q = SetToSeq(Tasks)
    /\ blocked_q = <<>>
    /\ lock_owner = ""
\end{tla}
\begin{tlatex}
\@x{ Init \.{\defeq}}%
 \@x{\@s{16.4} \.{\land} cpus \.{=} [ i \.{\in} 0 \.{\dotdot} N \.{-} 1
 \.{\mapsto}\@w{} ]}%
\@x{\@s{16.4} \.{\land} ready\_q \.{=} SetToSeq ( Tasks )}%
\@x{\@s{16.4} \.{\land} blocked\_q \.{=} {\langle} {\rangle}}%
\@x{\@s{16.4} \.{\land} lock\_owner \.{=}\@w{}}%
\end{tlatex}
\newline

A few things to note:
\begin{itemize}
    \item The system has \textit{N} executing context, represented as number of CPUs.
    When a task is running, \textit{cpus[k]} is set to \textit{taskName}. When CPU is idle,
    \textit{tcpus[k]} is set to an empty string. 
    \item \textit{ready\_q} and \textit{blocked\_q} are initialized as \textit{ordered tuple},
    due to the cooperative scheduling requirement.
    \item \textit{SetToSeq} is a macro from the community module \cite{tla_comm}
    to converts a set into a ordered tuple. To use community module, one can
    install required .tla files into the tla project source directly.
    \item \textit{lock\_owner} represents the task that is current holding the lock. 
\end{itemize}

A task can be in three possible state: \textit{Ready}, \textit{Blocked} and
\textit{Running}. The Spec describes required lock contention handling.\newline

\begin{tla}
Ready == 
    \E t \in DOMAIN ready_q:
        \E k \in DOMAIN cpus:
        /\ cpus[k] = "" 
        /\ cpus' = [cpus EXCEPT ![k] = Head(ready_q)]
        /\ ready_q' = Tail(ready_q)
        /\ UNCHANGED <<lock_owner, blocked_q>>
Running == 
    \E k \in DOMAIN cpus:
        \/ MoveToReady(k)
        \/ Lock(k)
        \/ Unlock(k)
Next == 
    \/ Running
    \/ Ready
\end{tla}
\begin{tlatex}
\@x{ Ready \.{\defeq}}%
\@x{\@s{16.4} \E\, t \.{\in} {\DOMAIN} ready\_q \.{:}}%
\@x{\@s{20.5} \E\, k \.{\in} {\DOMAIN} cpus \.{:}}%
\@x{\@s{20.5} \.{\land} cpus [ k ] \.{=}\@w{}}%
 \@x{\@s{20.5} \.{\land} cpus \.{'} \.{=} [ cpus {\EXCEPT} {\bang} [ k ] \.{=}
 Head ( ready\_q ) ]}%
\@x{\@s{20.5} \.{\land} ready\_q \.{'} \.{=} Tail ( ready\_q )}%
 \@x{\@s{20.5} \.{\land} {\UNCHANGED} {\langle} lock\_owner ,\, blocked\_q
 {\rangle}}%
\@x{ Running \.{\defeq}}%
\@x{\@s{16.4} \E\, k \.{\in} {\DOMAIN} cpus \.{:}}%
\@x{\@s{20.5} \.{\lor} MoveToReady ( k )}%
\@x{\@s{20.5} \.{\lor} Lock ( k )}%
\@x{\@s{20.5} \.{\lor} Unlock ( k )}%
\@x{ Next \.{\defeq}}%
\@x{\@s{16.4} \.{\lor} Running}%
\@x{\@s{16.4} \.{\lor} Ready}%
\end{tlatex}
\newline

Next can update either a task that is running, or a task waiting to be
scheduled.\newline

A \textit{Ready} task is popped off the ready queue and put onto a idle CPU.
Since ready\_q is implemented as an ordered tuple, fetching and popping the
front is done using \textit{Head} and \textit{Tail}, respectively.\newline

A \textit{Running} task can either go back to the ready queue (done for now),
acquire the global lock, or release the global lock.  The sub-actions are
defined below:\newline

\begin{tla}
MoveToReady(k) == 
    /\ cpus[k] # "" 
    /\ lock_owner # cpus[k]
    /\ ready_q' = Append(ready_q, cpus[k]) 
    /\ cpus' = [cpus EXCEPT ![k] = ""]
    /\ UNCHANGED <<lock_owner, blocked_q, blocked>>
\end{tla}
\begin{tlatex}
\@x{ MoveToReady ( k ) \.{\defeq}}%
\@x{\@s{16.4} \.{\land} cpus [ k ] \.{\neq}\@w{}}%
\@x{\@s{16.4} \.{\land} lock\_owner \.{\neq} cpus [ k ]}%
 \@x{\@s{16.4} \.{\land} ready\_q \.{'} \.{=} Append ( ready\_q ,\, cpus [ k ]
 )}%
 \@x{\@s{16.4} \.{\land} cpus \.{'} \.{=} [ cpus {\EXCEPT} {\bang} [ k ]
 \.{=}\@w{} ]}%
 \@x{\@s{16.4} \.{\land} {\UNCHANGED} {\langle} lock\_owner ,\, blocked\_q ,\,
 blocked {\rangle}}%
\end{tlatex}
\newline

\textit{MoveToReady} defines the where task voluntarily go back to ready
queue.\newline

\begin{tla}
Lock(k) == 
    \/  /\ cpus[k] # "" 
        /\ lock_owner = ""
        /\ lock_owner' = cpus[k]
        /\ UNCHANGED <<ready_q, cpus, blocked_q, blocked>> 
    \/  /\ cpus[k] # "" 
        /\ lock_owner # ""
        /\ lock_owner # cpus[k] \* cannot double lock
        /\ blocked_q' = Append(blocked_q, cpus[k])
        /\ blocked' = [blocked EXCEPT ![cpus[k]] = 1]
        /\ cpus' = [cpus EXCEPT ![k] = ""]
        /\ UNCHANGED <<ready_q, lock_owner>>
\end{tla}
\begin{tlatex}
\@x{ Lock ( k ) \.{\defeq}}%
\@x{ \.{\lor}\@s{4.1} \.{\land} cpus [ k ] \.{\neq}\@w{}}%
\@x{\@s{4.1} \.{\land} lock\_owner \.{=}\@w{}}%
\@x{\@s{4.1} \.{\land} lock\_owner \.{'} \.{=} cpus [ k ]}%
 \@x{\@s{4.1} \.{\land} {\UNCHANGED} {\langle} ready\_q ,\, cpus ,\,
 blocked\_q ,\, blocked {\rangle}}%
\@x{ \.{\lor}\@s{4.1} \.{\land} cpus [ k ] \.{\neq}\@w{}}%
\@x{\@s{4.1} \.{\land} lock\_owner \.{\neq}\@w{}}%
\@x{\@s{4.1} \.{\land} lock\_owner \.{\neq} cpus [ k ]}%
\@y{%
  cannot double lock
}%
\@xx{}%
 \@x{\@s{4.1} \.{\land} blocked\_q \.{'} \.{=} Append ( blocked\_q ,\, cpus [
 k ] )}%
 \@x{\@s{4.1} \.{\land} blocked \.{'} \.{=} [ blocked {\EXCEPT} {\bang} [ cpus
 [ k ] ] \.{=} 1 ]}%
 \@x{\@s{4.1} \.{\land} cpus \.{'} \.{=} [ cpus {\EXCEPT} {\bang} [ k ]
 \.{=}\@w{} ]}%
 \@x{\@s{4.1} \.{\land} {\UNCHANGED} {\langle} ready\_q ,\, lock\_owner
 {\rangle}}%
\end{tlatex}
\newline

\textit{Lock} represents when a running task attempts to acquire the global
lock. When the lock is free, the task grabs the lock and move on. When the lock 
is already held, the task moves into blocked queue to be scheduled when the lock
is released. If multiple tasks attempt to acquire the lock while the lock is
being held, the tasks will be inserted in the block queue in request order.
\newline

\begin{tla}
Unlock(k) == 
    \/  /\ cpus[k] # "" 
        /\ Len(blocked_q) # 0
        /\ lock_owner = cpus[k]
        /\ lock_owner' = Head(blocked_q)
        /\ cpus' = [cpus EXCEPT ![k] = Head(blocked_q)]
        /\ ready_q' = ready_q \o <<cpus[k]>>
        /\ blocked_q' = Tail(blocked_q)
        /\ blocked' = [blocked EXCEPT ![Head(blocked_q)] = 0]
    \/  /\ cpus[k] # "" 
        /\ Len(blocked_q) = 0
        /\ lock_owner' = ""
        /\ UNCHANGED <<ready_q, blocked_q, blocked, cpus>>
\end{tla}
\begin{tlatex}
\@x{ Unlock ( k ) \.{\defeq}}%
\@x{\@s{16.4} \.{\lor}\@s{4.1} \.{\land} cpus [ k ] \.{\neq}\@w{}}%
\@x{\@s{20.5} \.{\land} Len ( blocked\_q ) \.{\neq} 0}%
\@x{\@s{20.5} \.{\land} lock\_owner \.{=} cpus [ k ]}%
\@x{\@s{20.5} \.{\land} lock\_owner \.{'} \.{=} Head ( blocked\_q )}%
 \@x{\@s{20.5} \.{\land} cpus \.{'} \.{=} [ cpus {\EXCEPT} {\bang} [ k ] \.{=}
 Head ( blocked\_q ) ]}%
 \@x{\@s{20.5} \.{\land} ready\_q \.{'} \.{=} ready\_q \.{\circ} {\langle}
 cpus [ k ] {\rangle}}%
\@x{\@s{20.5} \.{\land} blocked\_q \.{'} \.{=} Tail ( blocked\_q )}%
 \@x{\@s{20.5} \.{\land} blocked \.{'} \.{=} [ blocked {\EXCEPT} {\bang} [
 Head ( blocked\_q ) ] \.{=} 0 ]}%
\@x{\@s{16.4} \.{\lor}\@s{4.10} \.{\land} cpus [ k ] \.{\neq}\@w{}}%
\@x{\@s{20.5} \.{\land} Len ( blocked\_q ) \.{=} 0}%
\@x{\@s{20.5} \.{\land} lock\_owner \.{'} \.{=}\@w{}}%
 \@x{\@s{20.5} \.{\land} {\UNCHANGED} {\langle} ready\_q ,\, blocked\_q ,\,
 blocked ,\, cpus {\rangle}}%
\end{tlatex}
\newline

\textit{Unlock} represents when a running task releases the lock. If there are
no blocked tasks, the running task carries on as before. If there are blocked
tasks, the first blocked task is scheduled to run immediately and running task
is inserted at the end of the ready queue. 

\section{Safety}

We can define safety property to detect programmatic failures. For example: if a
task is running on a CPU, this \textit{implies} task cannot be blocked:\newline

\begin{tla}
Safety ==
    \A t \in Tasks: 
        \A k \in 0..N-1:
            cpus[k] = t => blocked[t] = 0 
\end{tla}
\begin{tlatex}
\@x{ Safety \.{\defeq}}%
\@x{\@s{16.4} \A\, t \.{\in} Tasks \.{:}}%
\@x{\@s{20.5} \A\, k \.{\in} 0 \.{\dotdot} N \.{-} 1 \.{:}}%
\@x{\@s{24.6} cpus [ k ] \.{=} t \.{\implies} blocked [ t ] \.{=} 0}%
\end{tlatex}

\section{Liveness}

Any tasks attempting to acquire the lock when the lock is already taken becomes
blocked. A liveness property we can define is to check the scheduler gaurantee
any blocked task eventually acquire the lock and run. Before we describe this
liveness property, we need to first make sure no task can \textit{cannot} hold
onto the lock indefinitely (which is something the model checker \textit{will
try}):\newline

\begin{tla}
Fairness ==
    \A t \in Tasks :
        \A n \in 0..(N-1) :
            WF_vars(HoldingLock(t) /\ Unlock(n))
Spec ==
  /\ Init
  /\ [][Next]_vars
  /\ WF_vars(Next)
  /\ Fairness 
\end{tla}
\begin{tlatex}
\@x{ Fairness \.{\defeq}}%
\@x{\@s{16.4} \A\, t \.{\in} Tasks \.{:}}%
\@x{\@s{20.5} \A\, n \.{\in} 0 \.{\dotdot} ( N \.{-} 1 ) \.{:}}%
\@x{\@s{24.6} {\WF}_{ vars} ( HoldingLock ( t ) \.{\land} Unlock ( n ) )}%
\@x{ Spec \.{\defeq}}%
\@x{\@s{8.2} \.{\land} Init}%
\@x{\@s{8.2} \.{\land} {\Box} [ Next ]_{ vars}}%
\@x{\@s{8.2} \.{\land} {\WF}_{ vars} ( Next )}%
\@x{\@s{8.2} \.{\land} Fairness}%
\end{tlatex}
\newline

The weakness fairness description states that if the enabling condition for
\textit{HoldingLock} and \textit{Unlock} continuously stays true (eg. a lock is
being held and the task can unlock), the associated action, \textit{Unlock},
must \textit{always eventually} be called to satisfy the weak fairness
requirement. We can now define the liveness property: a task blocked waiting
for the lock \textit{leads to} the task acquiring the lock:\newline

\begin{tla}
Liveness == 
    \A t \in Tasks:
        blocked[t] = 1 ~> lock_owner = t
\end{tla}
\begin{tlatex}
\@x{ Liveness \.{\defeq}}%
\@x{\@s{16.4} \A\, t \.{\in} Tasks \.{:}}%
\@x{\@s{20.5} blocked [ t ] \.{=} 1 \.{\leadsto} lock\_owner \.{=} t}%
\end{tlatex}
\newline
